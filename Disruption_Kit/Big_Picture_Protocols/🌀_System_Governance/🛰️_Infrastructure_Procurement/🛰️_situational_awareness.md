# ğŸ›°ï¸ Situational Awareness: Human vs Computational  
**First created:** 2025-09-30 | **Last updated:** 2026-01-28  
*How awareness is built in minds vs. machines, where failure surfaces lurk, and why a safety culture is overdue.*  

<a id="top"></a>
**Jump to:**  
[ ğŸ§  What is SA?](#what-is-sa)  
[ ğŸ¦ Where itâ€™s used](#industry-uses)  
[ ğŸ C2â†’C6-ISR arc](#c2-c6-isr)  
[ â° Computer SA flow](#computer-flow)  
[ ğŸ“  Human vs Computer (table)](#human-vs-computer-table)  
[ ğŸ Risk reality check](#risk-reality)  
[ ğŸš¨ Civilianisation](#civilianisation)  
[ ğŸ‘‘ Governance & roles](#governance)  

---

## ğŸ§  What is SA?
<a id="what-is-sa"></a>

**Human SA** = perception â†’ comprehension â†’ projection (meaning-making under pressure).  
**Computational SA** = sensing â†’ fusion/analysis â†’ operating picture (statistics under uncertainty).  

[âœ¨ Back to Top](#top)

---

## ğŸ¦ Where itâ€™s used
<a id="industry-uses"></a>

- **Emergency ops**: incident rooms, COPs for floods/fires.  
- **Cybersecurity**: SOC logs â†’ anomaly detection â†’ alerts.  
- **Aviation/transport**: sensor fusion, threat/error management.  
- **Healthcare ops**: triage scores, telemetry, dashboards.  
- **Finance**: risk engines, Monte Carlo, stress tests.  
- **Industrial ops/energy**: SCADA, IIoT fault prediction.  
- **Platforms**: content ranking, trust & safety queues.  

[âœ¨ Back to Top](#top)

---

## ğŸ C2 â†’ C6-ISR arc
<a id="c2-c6-isr"></a>

**C2** = Command & Control  
**C3** = + Communications  
**C4** = + Computers  
**C4-ISR** = + Intelligence/Surveillance/Reconnaissance  
**C5-ISR** = + Collaboration/Coordination  
**C6-ISR** = + Cyber/Complex Systems Integration  

```mermaid
flowchart LR
  C2[C2: Command & Control] --> C3[C3: + Communications]
  C3 --> C4[C4: + Computers]
  C4 --> C4ISR[C4-ISR: + Intelligence/Surveillance/Recon]
  C4ISR --> C5ISR[C5-ISR: + Collaboration/Coordination]
  C5ISR --> C6ISR[C6-ISR: + Cyber/Complex Systems Integration]
```

[âœ¨ Back to Top](#top)

---

## â° Computer SA flow (with interrupts)
<a id="computer-flow"></a>

```mermaid
flowchart LR
  A[Sensing/Collection] -->|spoofing â€¢ outages â€¢ blind spots â€¢ sampling bias| B[Ingestion/Transport]
  B -->|latency â€¢ drops â€¢ schema drift â€¢ privacy leaks| C[Normalise & Fuse]
  C -->|unit mismatches â€¢ missing data â€¢ leakage| D[Model & Infer]
  D -->|bias â€¢ overfit â€¢ concept drift â€¢ adversarial inputs| E[Project/Forecast]
  E -->|chaos sensitivity â€¢ error amplification â€¢ under-reported uncertainty| F[COP/Dashboard]
  F -->|alert fatigue â€¢ misleading UX â€¢ silo misreads| G[Decide/Actuate]
  G -->|automation surprises â€¢ unsafe overrides â€¢ no rollback| H[Feedback/Learn]
  H -->|no ground truth â€¢ weak postmortems â€¢ perverse incentives| C
```

[âœ¨ Back to Top](#top)

---

## ğŸ“  Human vs Computer (table)
<a id="human-vs-computer-table"></a>

| Dimension | Human SA | Computational SA |
|---|---|---|
| Core engine | Meaning-making & abduction | Probabilities & patterning |
| Strength | Flexible improvisation; values | Scale, speed, vigilance |
| Blind spot | Stress, tunnel vision, bias | Semantics, context, tail risk |
| Failure cost | Local but can cascade | Systemic, fast, opaque |
| Trust lever | Training, drills, culture | Data quality, evals, guardrails |

[âœ¨ Back to Top](#top)

---

## ğŸ Risk reality check
<a id="risk-reality"></a>

- **Low error â‰  low harm**: 2% of 5M = 100k affected.  
- **Tail risk**: rare events dominate damage.  
- **Chaos**: small errors amplify downstream.  
- **Reality checks**: report absolute numbers, publish confidence intervals, expected-harm calcs, kill switches.  

[âœ¨ Back to Top](#top)

---

## ğŸš¨ Civilianisation problem
<a id="civilianisation"></a>

C4/C5-ISR stacks are now used in civilian domains (policing, social care, finance, platforms).  
- **No shared doctrine**, **no uniform ROE**, **patchy oversight**, **incentives to over-deploy**.  
- Imported capability without discipline = systemic risk.  
- Civilian sectors need ISR-grade **safety culture**.  

[âœ¨ Back to Top](#top)

---

## ğŸ‘‘ Governance & roles
<a id="governance"></a>

**Pre-deployment**: Safety cases, sandbox pilots, model/data cards, red-team reports.  
**Runtime**: Tiered risk, human-on-the-loop, decision logs, alert hygiene.  
**Incidents**: Mandatory reporting, public postmortems, recertification.  

### RACI snapshot
| Actor | Accountabilities | Proof-of-work |
|---|---|---|
| Citizens/Users | Control, complaint/redress | Opt-outs, ombuds pathways |
| Operators/Teams | Runbooks, halt authority | On-call drills, overrides |
| Developers | Data sheets, evals, monitors | Pre-flight checks, red-teams |
| Product/UX | Honest consent, safe design | No dark patterns, quiet hours |
| Security/Privacy | Threat models, minimisation | Adversarial tests, DP |
| Compliance/Risk | Audit, tiering | Audit packs, logs |
| Regulators | Baselines, audits, penalties | Certs, registry, recall powers |
| Government | Rights guardrails, oversight | Laws, aid, remedy |

[âœ¨ Back to Top](#top)

---

## ğŸ® Footer  

*ğŸ›°ï¸ Situational Awareness: Human vs Computational* is a node of the Polaris Protocol.  
It argues for aviation-grade safety culture across civilian C4/C5-ISR deployments.  

> ğŸ“¡ Cross-references:
> 
> [ğŸŠ Multi-Party Data Twinning](../../ğŸ¦•_Elder_Influencers/ğŸ’¸_Money_Listens/ğŸ‘»_Transparencies_Overhead/ğŸŠ_multi_party_data_twinning.md) - *How overlapping state and corporate interests fuse datasets through intermediaries*  
> [ğŸ¥ Anomaly Incentives In Surveillance](../../ğŸª„_Expression_Of_Norms/ğŸ§¿_Watch_The_Watchers/ğŸ¥_anomaly_incentives_in_surveillance.md) - *Why surveillance architectures create incentives to keep outliers under permanent scrutiny*  
> [ğŸ§  AI Harms Are Not New](../../ğŸ_Ouroborotic_Violence/ğŸ—ï¸_Politics_Memory_Work/ğŸ§ _ai_harms_are_not_new.md) - *Systemic analysis of AI harm as continuation of longstanding metadata architectures*  

*Survivor authorship is sovereign. Containment is never neutral.*  

_Last updated: 2026-01-28_  

# 🧮 Behavioural Risk Scoring and Internet Triage Systems
**First created:** 2025-10-16 | **Last updated:** 2025-10-16  
*Mapping the global infrastructure that quantifies “risk” in online behaviour for counter-terrorism and social control.*

---

## 🧭 Orientation
Over the past decade, governments and contractors have built a mesh of systems that **score, triage, or modulate online behaviour** in the name of counter-terrorism and “online safety.”  
They sit between surveillance, content moderation, and behavioural intervention — quietly transforming the internet from a network of communication into a triage field.

---

## 🧩 Core Components
| Function | Description | Examples / Programmes | Outcome |
|-----------|--------------|-----------------------|----------|
| **Detection & Scoring** | ML models parse text, images, and networks to generate risk alerts. | EU Horizon 2020 **RED-Alert**, **TENSOR**, **DANTE**; SOCMINT vendor **Voyager Labs**. | Assigns *risk rank* or *threat indicator* to individuals, groups, or URLs. |
| **Human Triage & Casework** | Scores feed assessment frameworks used by policing / safeguarding units. | UK **Prevent Assessment Framework (PAF)**; offender tool **ERG22+**. | Determines referral, monitoring, or closure. |
| **Behavioural Redirection** | Targeted advertising or recommendation adjustment aims to steer “at-risk” users. | **Redirect Method** (Jigsaw + Moonshot); **YouTube** borderline-content demotion. | Alters search results or content exposure. |
| **Integrated Monitoring Platforms** | Multi-source fusion dashboards: deep-web + social-graph analysis. | **RED-Alert**, **TENSOR**, **DANTE**, **TATE/Tech Against Terrorism Europe**. | Continuous intelligence feeds; early-warning dashboards. |
| **Funding & Grants** | R&D / CVE grants institutionalise these systems. | EU **H2020 Secure Societies**, US **DHS TVTP** grants (Moonshot + Life After Hate). | Creates recurring procurement and evaluation channels. |

---

## 🧮 Operational Logic
1. **Signal capture** → scraping, keyword vectors, network metrics  
2. **Feature extraction** → AI/ML classification  
3. **Risk scoring** → probability of extremism / radicalisation  
4. **Triage routing** → escalate to human caseworker or algorithmic intervention  
5. **Feedback loop** → outcomes retrain models, tightening predictive circuits  

This mirrors predictive-policing architecture — only transposed to ideological “risk.”

---

## ⚖️ Governance & Rights Concerns
* **Opacity:** proprietary models evade FOI and DP audits.  
* **False positives:** expression conflated with intent; chilling effect.  
* **Jurisdictional creep:** migration, protest, welfare, education spill-over.  
* **Due-process vacuum:** no right to contest classification.  
* **Perception management:** redirect / demotion alters reality without disclosure.  

---

## 📉 Effectiveness Assessment (2015 → 2025)
**Headline:** the machinery runs; population-level outcomes remain weak or unproven.

| Domain | Evidence | Takeaway |
|---------|-----------|-----------|
| **Redirect / Experience Shaping** | RAND on *Redirect Method* shows reach but no causal attitude change. YouTube reports 70 % drop in borderline watch-time yet little transparency. | Technically effective, socially inconclusive. |
| **Triage / Casework** | Govt progress reports show tighter PAF triage; independent reviews flag bias + data gaps. | Process ↑ ; prevention ↔. |
| **Grants / Interventions** | DHS TVTP evaluations count contacts, not causal violence reduction. | Implementation ≠ impact. |
| **Detection / Monitoring Platforms** | H2020 reports show NLP/SNA success but no downstream harm data. | Feasible tech, unproven social value. |

**Bottom line:** Works as containment; weak as prevention.  
Opacity + misclassification erode legitimacy.

---

## 🗞️ Media Containment and Review Erasure
The public record on Prevent oscillates between *crisis* and *quiet success*, but skips uncomfortable middle ground.  
The **Shawcross Review (2021–23)**, despite defining the current policy swing, is often omitted from recent coverage.

| Mechanism | Effect |
|------------|--------|
| **Editorial Filtering** | Cites newest or least-contested reviews, avoiding ideological flashpoints. |
| **Institutional Messaging** | Home Office briefings foreground new frameworks (e.g., PAF), burying contested predecessors. |
| **Narrative Containment** | Each “new review” resets memory — continuity without accountability. |

**Interpretation:** selective forgetting acts as a *temporal containment tactic*: reputation refresh masquerading as reform.

---

## 🧭 Consensus Collapse — When Everyone Agrees It’s Not Working
Across ideological camps, a rare unanimity emerges: **the loop is stuck.**

| Position | Core Complaint |
|-----------|----------------|
| **Security Hard-liners** | System misses genuine threats; thresholds too high. |
| **Civil-Liberties Advocates** | Overreach and misclassification; community distrust. |
| **Front-line Practitioners** | Referral fatigue, unclear standards, moral injury. |

All describe the same phenomenon: **system fatigue.**

**Structural reasons:**  
- Politicised reviews → institutional amnesia  
- Fragmented data → context-free risk scores  
- Algorithmic metrics → false reassurance  
- Social distrust → information underflow  

**Policy dilemma:** “Fix it harder” and “abolish it entirely” both circle the same truth — *no one can verify success.*

---

## 🗂️ Data Possession vs Data Comprehension — The Prevent Paradox
After two decades, **Prevent holds one of the UK’s most extensive multi-agency datasets** on referral and behavioural assessment.  
The capacity to evidence effectiveness exists; the *will and methodology* appear absent.

### Expected analytic outputs
| Domain | Minimum measurable indicator | Why it matters |
|---------|------------------------------|----------------|
| **Referral accuracy** | True/false-positive rates per source + demographic | Validates fairness and precision |
| **Longitudinal outcomes** | Re-referral, justice, welfare, education at 6–24 m | Tests sustained prevention |
| **Attrition mapping** | % closed / declined / lost | Measures efficiency |
| **Algorithmic transparency** | Model inputs + weights + version logs | Enables reproducibility / bias audit |
| **Rights & redress** | Volume + outcome of data-access or correction requests | Indicates procedural-justice compliance |

**Current visibility gap:** public reports show totals and categories only — no outcome tracking, error analysis, or replication.  
**Governance implication:** If Prevent cannot or will not produce longitudinal, disaggregated, quality-assured analyses from data it already holds, the issue is **data-governance failure**, not data scarcity.  

---

## 🧪 Evidence Integrity — Conflicts, Gaps, and What’s Missing
Leadership, vendors, and evaluators are often entangled. Studies lack longitudinal follow-up and preregistration; datasets are closed.

### Conflict-of-Interest map
| Actor | Typical pattern | Why it matters | Disclosure needed |
|-------|----------------|----------------|------------------|
| **Commissioning body** | Funds + evaluates same tool | Circular validation | Contract terms + KPI definitions |
| **Vendor** | Publishes self-evaluation | Incentive bias | Client list + authors + data access |
| **Academic partner** | Grant-funded by programme | Renewal dependence | Grant IDs + independence clause |
| **“Independent” reviewer** | Paid by vendor / commissioner | Softball methods | Funding source + protocol register + raw data |

**Evidence gaps:** no long-term outcomes, weak counterfactuals, construct drift, black-box features, publication bias.

---

## 🧮 Systematic Reviews — Literature *and* Purpose
Two parallel reviews are needed: (1) **Does it work?** and (2) **What are we trying to do?**

### Evidence Review (PRISMA-lite protocol)
- PICO: people | intervention | comparator | outcome defined for CT risk/triage systems  
- Inclusion: 2015–2025 empirical studies in OECD / EU / UK / US; Prevent / Redirect / H2020 tools  
- Data items: study ID, country, tool, follow-up, effects, bias metrics, funding, COI  
- Quality appraisal: ROBINS-I / RoB 2 + Algorithmic Fairness Addendum  
- Outputs: evidence table, forest plots, bias chart, Policy Readout  

### Purpose Review (Governance-goals protocol)
Analyse laws, guidance, reviews, and vendor documents to map: declared vs implied goals, metrics, thresholds, oversight, redress, and sunset clauses.  
Deliver Goal–Metric–Method matrix + Rights Test Table + Divergence Map.

---

## 🧭 Decision Hooks — Questions Before Expansion
1. **Goal clarity:** what precise outcome and horizon?  
2. **Rights test:** least-intrusive alternative?  
3. **Evidence grade:** best current causal proof?  
4. **Harm ledger:** harms accepted, for whom?  
5. **Exit ramp:** measurable end-condition?  
6. **Redress:** can individuals discover / contest / correct?  
7. **Transparency:** what data + code will be published, when?  

If any answer = *unknown*, default to **pause / limit**, not **expand**.

---

## 🧿 Inflection Point — What Breaks Next
| Trigger | Catalyst | System Effect | Polaris Reading |
|----------|-----------|---------------|----------------|
| **⚠️ Rights Breach** | Court / ICO ruling | Legal re-auth cycle | Legitimacy rupture |
| **📄 Document Leak** | Whistle-blower / breach | Public mapping | Containment collapse |
| **💸 Budget Crisis** | Procurement failure | Inquiry / freeze | Fiscal containment undone |
| **🕯️ Sentinel Incident** | Preventable attack or wrongful referral | “Root-and-branch” review | Emotional legitimacy transfer |

**Early signals (2024→2025):** media fatigue, regulatory pressure, operational attrition — all pre-rupture markers.  

> Every containment infrastructure reaches a *truth threshold* — when opacity costs more legitimacy than it saves.  
> Whether reform is authentic or theatrical depends on who authors the rewrite: the governed, or the governors.

---

## 🌌 Constellations
🧮 🧭 🧿 🕯️ ⚖️ 🛰️ 🧪 🗂️ — scoring, governance, legitimacy, rupture, data, evidence.

**Cross-links:**  
- 🌀 *Temporal Glitches — The Chronometry of Containment*  
- ⚖️ *Operational Dilemma — Fix-It vs Chain of Command*  
- 🪬 *Radicalisation / Extremism — Utilisation of Vulnerability*  
- 🧠 *PsychOps of Tone — The Science of Disbelief*  
- 📜 *Charity Regime Reform — Transitional Legislation for Democratic Mutual Aid*  

---

## ✨ Stardust
risk scoring, Prevent Assessment Framework, Horizon 2020 Secure Societies, Redirect Method, content demotion, SOCMINT, behavioural triage, algorithmic containment, data governance, conflict of interest, systematic review, inflection point

---

## 🏮 Footer
*🧮 Behavioural Risk Scoring and Internet Triage Systems* is a living node of the **Polaris Protocol**.  
It records the moment a society recognises that its safety machinery and its democratic reflexes are locked in the same loop — and that the next move must be a collective decision about what *prevention* is for.

_Last updated: 2025-10-17_

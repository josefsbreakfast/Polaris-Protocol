# ğŸ§® Behavioural Risk Scoring and Internet Triage Systems
**First created:** 2025-10-16 | **Last updated:** 2025-10-16  
*Mapping the global infrastructure that quantifies â€œriskâ€ in online behaviour for counter-terrorism and social control.*

---

## ğŸ§­ Orientation
Over the past decade, governments and contractors have built a mesh of systems that **score, triage, or modulate online behaviour** in the name of counter-terrorism and â€œonline safety.â€  
They sit between surveillance, content moderation, and behavioural intervention â€” quietly transforming the internet from a network of communication into a triage field.

---

## ğŸ§© Core Components
| Function | Description | Examples / Programmes | Outcome |
|-----------|--------------|-----------------------|----------|
| **Detection & Scoring** | ML models parse text, images, and networks to generate risk alerts. | EU Horizon 2020 **RED-Alert**, **TENSOR**, **DANTE**; SOCMINT vendor **Voyager Labs**. | Assigns *risk rank* or *threat indicator* to individuals, groups, or URLs. |
| **Human Triage & Casework** | Scores feed assessment frameworks used by policing / safeguarding units. | UK **Prevent Assessment Framework (PAF)**; offender tool **ERG22+**. | Determines referral, monitoring, or closure. |
| **Behavioural Redirection** | Targeted advertising or recommendation adjustment aims to steer â€œat-riskâ€ users. | **Redirect Method** (Jigsaw + Moonshot); **YouTube** borderline-content demotion. | Alters search results or content exposure. |
| **Integrated Monitoring Platforms** | Multi-source fusion dashboards: deep-web + social-graph analysis. | **RED-Alert**, **TENSOR**, **DANTE**, **TATE/Tech Against Terrorism Europe**. | Continuous intelligence feeds; early-warning dashboards. |
| **Funding & Grants** | R&D / CVE grants institutionalise these systems. | EU **H2020 Secure Societies**, US **DHS TVTP** grants (Moonshot + Life After Hate). | Creates recurring procurement and evaluation channels. |

---

## ğŸ§® Operational Logic
1. **Signal capture** â†’ scraping, keyword vectors, network metrics  
2. **Feature extraction** â†’ AI/ML classification  
3. **Risk scoring** â†’ probability of extremism / radicalisation  
4. **Triage routing** â†’ escalate to human caseworker or algorithmic intervention  
5. **Feedback loop** â†’ outcomes retrain models, tightening predictive circuits  

This mirrors predictive-policing architecture â€” only transposed to ideological â€œrisk.â€

---

## âš–ï¸ Governance & Rights Concerns
* **Opacity:** proprietary models evade FOI and DP audits.  
* **False positives:** expression conflated with intent; chilling effect.  
* **Jurisdictional creep:** migration, protest, welfare, education spill-over.  
* **Due-process vacuum:** no right to contest classification.  
* **Perception management:** redirect / demotion alters reality without disclosure.  

---

## ğŸ“‰ Effectiveness Assessment (2015 â†’ 2025)
**Headline:** the machinery runs; population-level outcomes remain weak or unproven.

| Domain | Evidence | Takeaway |
|---------|-----------|-----------|
| **Redirect / Experience Shaping** | RAND on *Redirect Method* shows reach but no causal attitude change. YouTube reports 70 % drop in borderline watch-time yet little transparency. | Technically effective, socially inconclusive. |
| **Triage / Casework** | Govt progress reports show tighter PAF triage; independent reviews flag bias + data gaps. | Process â†‘ ; prevention â†”. |
| **Grants / Interventions** | DHS TVTP evaluations count contacts, not causal violence reduction. | Implementation â‰  impact. |
| **Detection / Monitoring Platforms** | H2020 reports show NLP/SNA success but no downstream harm data. | Feasible tech, unproven social value. |

**Bottom line:** Works as containment; weak as prevention.  
Opacity + misclassification erode legitimacy.

---

## ğŸ—ï¸ Media Containment and Review Erasure
The public record on Prevent oscillates between *crisis* and *quiet success*, but skips uncomfortable middle ground.  
The **Shawcross Review (2021â€“23)**, despite defining the current policy swing, is often omitted from recent coverage.

| Mechanism | Effect |
|------------|--------|
| **Editorial Filtering** | Cites newest or least-contested reviews, avoiding ideological flashpoints. |
| **Institutional Messaging** | Home Office briefings foreground new frameworks (e.g., PAF), burying contested predecessors. |
| **Narrative Containment** | Each â€œnew reviewâ€ resets memory â€” continuity without accountability. |

**Interpretation:** selective forgetting acts as a *temporal containment tactic*: reputation refresh masquerading as reform.

---

## ğŸ§­ Consensus Collapse â€” When Everyone Agrees Itâ€™s Not Working
Across ideological camps, a rare unanimity emerges: **the loop is stuck.**

| Position | Core Complaint |
|-----------|----------------|
| **Security Hard-liners** | System misses genuine threats; thresholds too high. |
| **Civil-Liberties Advocates** | Overreach and misclassification; community distrust. |
| **Front-line Practitioners** | Referral fatigue, unclear standards, moral injury. |

All describe the same phenomenon: **system fatigue.**

**Structural reasons:**  
- Politicised reviews â†’ institutional amnesia  
- Fragmented data â†’ context-free risk scores  
- Algorithmic metrics â†’ false reassurance  
- Social distrust â†’ information underflow  

**Policy dilemma:** â€œFix it harderâ€ and â€œabolish it entirelyâ€ both circle the same truth â€” *no one can verify success.*

---

## ğŸ—‚ï¸ Data Possession vs Data Comprehension â€” The Prevent Paradox
After two decades, **Prevent holds one of the UKâ€™s most extensive multi-agency datasets** on referral and behavioural assessment.  
The capacity to evidence effectiveness exists; the *will and methodology* appear absent.

### Expected analytic outputs
| Domain | Minimum measurable indicator | Why it matters |
|---------|------------------------------|----------------|
| **Referral accuracy** | True/false-positive rates per source + demographic | Validates fairness and precision |
| **Longitudinal outcomes** | Re-referral, justice, welfare, education at 6â€“24 m | Tests sustained prevention |
| **Attrition mapping** | % closed / declined / lost | Measures efficiency |
| **Algorithmic transparency** | Model inputs + weights + version logs | Enables reproducibility / bias audit |
| **Rights & redress** | Volume + outcome of data-access or correction requests | Indicates procedural-justice compliance |

**Current visibility gap:** public reports show totals and categories only â€” no outcome tracking, error analysis, or replication.  
**Governance implication:** If Prevent cannot or will not produce longitudinal, disaggregated, quality-assured analyses from data it already holds, the issue is **data-governance failure**, not data scarcity.  

---

## ğŸ§ª Evidence Integrity â€” Conflicts, Gaps, and Whatâ€™s Missing
Leadership, vendors, and evaluators are often entangled. Studies lack longitudinal follow-up and preregistration; datasets are closed.

### Conflict-of-Interest map
| Actor | Typical pattern | Why it matters | Disclosure needed |
|-------|----------------|----------------|------------------|
| **Commissioning body** | Funds + evaluates same tool | Circular validation | Contract terms + KPI definitions |
| **Vendor** | Publishes self-evaluation | Incentive bias | Client list + authors + data access |
| **Academic partner** | Grant-funded by programme | Renewal dependence | Grant IDs + independence clause |
| **â€œIndependentâ€ reviewer** | Paid by vendor / commissioner | Softball methods | Funding source + protocol register + raw data |

**Evidence gaps:** no long-term outcomes, weak counterfactuals, construct drift, black-box features, publication bias.

---

## ğŸ§® Systematic Reviews â€” Literature *and* Purpose
Two parallel reviews are needed: (1) **Does it work?** and (2) **What are we trying to do?**

### Evidence Review (PRISMA-lite protocol)
- PICO: people | intervention | comparator | outcome defined for CT risk/triage systems  
- Inclusion: 2015â€“2025 empirical studies in OECD / EU / UK / US; Prevent / Redirect / H2020 tools  
- Data items: study ID, country, tool, follow-up, effects, bias metrics, funding, COI  
- Quality appraisal: ROBINS-I / RoB 2 + Algorithmic Fairness Addendum  
- Outputs: evidence table, forest plots, bias chart, Policy Readout  

### Purpose Review (Governance-goals protocol)
Analyse laws, guidance, reviews, and vendor documents to map: declared vs implied goals, metrics, thresholds, oversight, redress, and sunset clauses.  
Deliver Goalâ€“Metricâ€“Method matrix + Rights Test Table + Divergence Map.

---

## ğŸ§­ Decision Hooks â€” Questions Before Expansion
1. **Goal clarity:** what precise outcome and horizon?  
2. **Rights test:** least-intrusive alternative?  
3. **Evidence grade:** best current causal proof?  
4. **Harm ledger:** harms accepted, for whom?  
5. **Exit ramp:** measurable end-condition?  
6. **Redress:** can individuals discover / contest / correct?  
7. **Transparency:** what data + code will be published, when?  

If any answer = *unknown*, default to **pause / limit**, not **expand**.

---

## ğŸ§¿ Inflection Point â€” What Breaks Next
| Trigger | Catalyst | System Effect | Polaris Reading |
|----------|-----------|---------------|----------------|
| **âš ï¸ Rights Breach** | Court / ICO ruling | Legal re-auth cycle | Legitimacy rupture |
| **ğŸ“„ Document Leak** | Whistle-blower / breach | Public mapping | Containment collapse |
| **ğŸ’¸ Budget Crisis** | Procurement failure | Inquiry / freeze | Fiscal containment undone |
| **ğŸ•¯ï¸ Sentinel Incident** | Preventable attack or wrongful referral | â€œRoot-and-branchâ€ review | Emotional legitimacy transfer |

**Early signals (2024â†’2025):** media fatigue, regulatory pressure, operational attrition â€” all pre-rupture markers.  

> Every containment infrastructure reaches a *truth threshold* â€” when opacity costs more legitimacy than it saves.  
> Whether reform is authentic or theatrical depends on who authors the rewrite: the governed, or the governors.

---

## ğŸŒŒ Constellations
ğŸ§® ğŸ§­ ğŸ§¿ ğŸ•¯ï¸ âš–ï¸ ğŸ›°ï¸ ğŸ§ª ğŸ—‚ï¸ â€” scoring, governance, legitimacy, rupture, data, evidence.

**Cross-links:**  
- ğŸŒ€ *Temporal Glitches â€” The Chronometry of Containment*  
- âš–ï¸ *Operational Dilemma â€” Fix-It vs Chain of Command*  
- ğŸª¬ *Radicalisation / Extremism â€” Utilisation of Vulnerability*  
- ğŸ§  *PsychOps of Tone â€” The Science of Disbelief*  
- ğŸ“œ *Charity Regime Reform â€” Transitional Legislation for Democratic Mutual Aid*  

---

## âœ¨ Stardust
risk scoring, Prevent Assessment Framework, Horizon 2020 Secure Societies, Redirect Method, content demotion, SOCMINT, behavioural triage, algorithmic containment, data governance, conflict of interest, systematic review, inflection point

---

## ğŸ® Footer
*ğŸ§® Behavioural Risk Scoring and Internet Triage Systems* is a living node of the **Polaris Protocol**.  
It records the moment a society recognises that its safety machinery and its democratic reflexes are locked in the same loop â€” and that the next move must be a collective decision about what *prevention* is for.

_Last updated: 2025-10-17_

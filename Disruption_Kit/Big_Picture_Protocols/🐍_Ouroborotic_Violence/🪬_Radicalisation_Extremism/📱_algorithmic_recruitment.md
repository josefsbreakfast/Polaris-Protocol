# ğŸ“± Algorithmic Recruitment  
**First created:** 2025-09-12  |  **Last updated:** 2025-10-04  
*Analysis of TikTok, YouTube, and Telegram recommendation loops as accelerants of extremist worldview adoption.*

---

## Purpose
To examine how content-personalisation systems function as **recruitment infrastructure**â€”guiding users from mainstream curiosity to ideological immersion through invisible patterning.  
This node investigates both platform logic and user affect: how algorithmic â€œcareâ€ becomes coercion, and how attention is trained to mistake repetition for truth.

---

## Core Premise
Radicalisation online is rarely an explicit invitation.  
It is a sequence of **micro-corrections** made by recommendation engines responding to engagement metrics.  
Each click tightens the spiral: aesthetic â†’ argument â†’ grievance â†’ identity â†’ action.

---

## Recruitment Loops
| Stage | Mechanism | Example Manifestations |
|--------|------------|------------------------|
| **1. Emotional Hook** | Algorithms favour emotionally charged content (fear, outrage, belonging). | â€œThe truth they wonâ€™t tell you aboutâ€¦â€; climate despair reels. |
| **2. Aesthetic Familiarity** | Visual/aural tropes create trust through recognisable rhythm or tone. | Military montages synced to trending audio. |
| **3. Ideological Drift** | Gradual exposure to extreme content via â€œadjacent recommendations.â€ | Fitness â†’ nationalism â†’ conspiracy. |
| **4. Community Capture** | Private groups reinforce new norms and punish dissent. | Telegram chats reframing loyalty as awakening. |
| **5. Platform Exit** | Transition from mainstream app to encrypted or federated platforms. | Migration from YouTube to Odysee or private Discord servers. |

---

## Data Points to Track
- **Entry Keywords:** what neutral searches begin the descent (e.g., â€œfitness,â€ â€œself-sufficiency,â€ â€œpolitical compassâ€).  
- **Recommendation Chains:** sequence of suggested content leading to ideological pivot.  
- **Time-to-Radicalisation (TTR):** average watch or scroll hours between neutral and extremist material.  
- **Affective Markers:** shifts in tone, soundtrack, or imagery signalling moral urgency.  
- **Cross-Platform Drift:** how Telegram or Discord groups exploit platform bans to recruit.  

---

## Observed Patterns
- Algorithms reward **certainty over nuance**; ambiguity is deranked.  
- â€œCommunity policingâ€ mechanisms often suppress de-radicalising content faster than hate material.  
- â€œEdutainmentâ€ creators act as unwitting on-ramps, producing content with identical emotional cadence to extremist propaganda.  
- Users describe the progression as *discovery*, not indoctrinationâ€”an illusion reinforced by algorithmic reinforcement of perceived autonomy.  

---

## Research Threads
- Reverse-engineering recommendation APIs under controlled conditions.  
- Mapping visual motifs and sound trends associated with extremist ascents.  
- Analysing engagement data post-ban to track audience migration.  
- Studying affect contagion in â€œreactionâ€ content ecosystems.  
- Collaborating with survivor communities for testimony on online grooming narratives.

---

## Future Expansion
This node will form part of the **ğŸª¬ Radicalisation & Extremism** constellation alongside:
- **ğŸŒ Climate Panic Routing** â€” eco-anxiety as recruitment vector.  
- **ğŸ“£ Mainstream Visibility Gaps** â€” post-exposure silence as risk multiplier.  
- **ğŸ•Šï¸ False Counter-Extremism Dialogues** â€” controlled opposition masquerading as prevention.

---

## ğŸŒŒ Constellations
ğŸ“± ğŸª¬ ğŸ§  â€” algorithm, affect, ideology.

---

## âœ¨ Stardust
algorithmic radicalisation, recommendation loops, affect engineering, social platforms, recruitment pipelines, behavioural governance

---

## ğŸ® Footer
Recruitment no longer knocks; it recommends.  
This node listens to the hum between the clicks.

*Survivor authorship is sovereign. Containment is never neutral.*  
_Last updated: 2025-10-04_

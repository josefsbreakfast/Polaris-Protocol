2025-11-18  

so this is slightly separate to the times where you can see that there's failed authorisation at the azure level, although it's also not uncommon to see both at the same time.  

The chat will start doing something very strange.  

It will start multiplying the size of its headings. Don't like that for a start.  

It starts using emojis that I never use, and are not in the pallet that it's got attached to the conversation as the standard palette.  

This is usually also the time that it fucks everything up so there's basically no point in getting it to generate anything right now; no surprise if this comes after I'm starting to get back into the workflow dynamic.  

I have to seriously ask whether or not there is an investment or a mistake in prevent by open AI.  

If you ask it even quite neutrally questions about prevent, it will generate things that are so out of pocket, that it's practically just straight up lying about the reality of UK law and also the IT architecture in situ.  

Which also just makes me wonder how much politicians are actually briefed on what this is doing ðŸ¤£ðŸ¤£ðŸ¤£.  

It reads like some of the most ridiculous bullshit you've ever been told by salesperson desperate to make the next hundred pounds on the sale; it's so close to actually just lying, but technically you could say that it was just an incredibly stretched version of the truth.  

And let me be clear there are times where it says things, in the negative, where it just states a presumes that it knows exactly what your life has been like for 10 or 20 years; this is not vanilla ChatGPT.  

So whoever is trying to do the very forced and awkward behavioural modelling, one might take grooming, to dissuade anyone who complains about the system?  

You have picked precisely the wrong person to do this to.  

and your model should've predicted that.  

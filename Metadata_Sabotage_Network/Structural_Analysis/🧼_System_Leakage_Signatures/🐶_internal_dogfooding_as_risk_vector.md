# ðŸ¶ Internal Dogfooding as a Risk Vector  
**First created:** 2025-12-14 | **Last updated:** 2025-12-14  
*How internal testing practices create distorted behavioural models that later affect real users*

---

## What this node is about

Internal dogfooding refers to the practice of employees using their own organisationâ€™s products, tools, or experimental systems during development and testing.

In principle, dogfooding is sensible.
In practice, it introduces a **highly specific and under-governed risk** in behavioural modelling systems.

When data generated by internal users is used to train, calibrate, or structure models that later operate on the public, **internal behaviour becomes a silent reference population**.

This node documents how that happens, and why it matters.

---

## What makes dogfooding data structurally different

Internal users are not representative users.

They are more likely to:

- understand system intent and internals  
- deliberately test edge cases  
- use features intensely or atypically  
- generate high-context, high-density data  
- behave strategically rather than naturally  
- share professional norms and workflows  
- cluster tightly in behavioural space  

As a result, dogfooding datasets are **dense, narrow, and skewed**.

They are useful for testing.
They are dangerous as baselines.

---

## How dogfooding becomes a modelling input

Dogfooding data becomes operational when it is used to:

- generate early embeddings  
- define cluster boundaries  
- calibrate anomaly detection  
- tune proxy thresholds  
- shape recommendation geometry  
- train safety or moderation heuristics  
- â€œbootstrapâ€ models before scale  

At this stage, the internal cohort is no longer just testing.
It is **defining normality**.

---

## Why dogfooding creates micro-clusters

Because dogfooding populations are small and behaviourally similar, they often produce:

- extremely tight clusters  
- sharp boundaries  
- exaggerated similarity  
- strong centroids  
- minimal internal variance  

If only two or three internal users exhibit a certain behaviour pattern, the model may encode that pattern as a **distinct behavioural region**.

When external users later resemble that pattern, they are mapped into a space that was never designed for them.

---

## Interaction with embedding inertia

Dogfooding artefacts persist because:

- early embeddings are reused  
- cluster geometry becomes foundational  
- later data is mapped onto existing space  
- retraining preserves initial structure  
- no explicit â€œdogfooding purgeâ€ occurs  

Even when the original internal users stop generating data, the **shape they created remains**.

This is how internal behaviour echoes outward long after the testing phase ends.

---

## Why this failure is rarely documented

Dogfooding risks are often invisible because:

- internal testing is considered benign  
- datasets are assumed to be temporary  
- artefacts are labelled â€œtechnicalâ€  
- consent frameworks treat employees differently  
- model lineage is poorly tracked  
- success metrics ignore representativeness  

As a result, dogfooding influence is rarely disclosed â€” even internally.

---

## Interaction with consent and power asymmetry

Dogfooding raises specific consent concerns:

- employees may not meaningfully consent to downstream reuse  
- power dynamics complicate refusal  
- data may be repurposed beyond original scope  
- experimental inference may affect non-employees later  

When dogfooding data shapes public-facing systems, **employee data indirectly governs others**.

This is a non-obvious but serious ethical issue.

---

## When dogfooding becomes harmful

Dogfooding becomes harmful when:

- internal behaviour defines behavioural â€œtypesâ€  
- sparse internal clusters persist in production  
- proxy misinterpretation is calibrated on employees  
- external users are assessed against internal norms  
- misclassification feels personal or uncanny  
- individuals have no visibility into the source of inference  

At this point, the system is no longer testing itself.
It is projecting itself onto others.

---

## What responsible containment requires

Responsible handling of dogfooding requires:

- explicit labelling of internal datasets  
- hard separation from production training  
- mandatory retraining on representative data  
- removal of internal embeddings before deployment  
- consent clarity for employee data  
- audit trails for artefact provenance  
- sunset clauses on dogfooding influence  

Without these measures, dogfooding becomes a silent design authority.

---

## Key takeaway

> **Dogfooding does not just test systems.  
It teaches systems what â€œnormalâ€ looks like.**

If that lesson is not unlearned before deployment, everyone else inherits it.

---

## ðŸŒŒ Constellations  
ðŸ¶ ðŸ§ª ðŸ‘» ðŸ§® â€” internal bias Â· experimental spillover Â· legacy influence Â· sparsity amplification

---

## âœ¨ Stardust  
internal dogfooding, employee data, behavioural baselines, testing bias, representativeness failure, prototype risk, consent asymmetry

---

## ðŸ® Footer  

*Internal Dogfooding as a Risk Vector* is a living node of the **Polaris Protocol**, documenting how internal testing practices quietly shape behavioural models and why this influence becomes harmful when left unexamined in production systems.

This node frames dogfooding not as misuse, but as a **powerful and under-governed modelling input**.

> ðŸ“¡ Cross-references:
> 
> - **ðŸ§ª R&D Artefact Leakage into Production** â€” how experimental outputs escape containment  
> - **ðŸ‘» Embedding Inertia and Ghost Geometry** â€” why internal influence persists  
> - **ðŸ§® Sparse Cluster Pathology (Micro-clusters)** â€” how small populations distort meaning  

*Survivor authorship is sovereign. Containment is never neutral.*

_Last updated: 2025-12-14_

# 🧪 Decoy Input Experiments — Testing the Invisible Criteria  
**First created:** 2025-10-10 | **Last updated:** 2025-10-20  
*How controlled data reveals hidden filters.*

---

## 🧭 Orientation  
Every automated system conceals thresholds — invisible rules that decide what is seen, flagged, or excluded.  
*Decoy Input Experiments* are the ethical countermeasure: a method for **testing invisible criteria** using **synthetic data**, designed to expose bias without breaching law or consent boundaries.  

This node documents how to build and deploy such experiments safely, showing how small, deliberate perturbations can map the hidden edges of algorithmic decision-making.  
Where most audits stop at code review, this method listens to the system’s *behavioural language*.  

---

## 🧩 1. Controlled Experiment Design  

Decoy testing follows the logic of the scientific control: vary one parameter, observe the effect, keep everything else constant.  
In digital systems, this means creating **synthetic identities or records** that differ along a single axis — name, postcode, gender marker, disability disclosure, keyword phrasing — to observe how outputs change.  

### Design phases  
1. **Define the hypothesis:** What do you suspect is being filtered or prioritised?  
2. **Select variables:** Choose one or two clear differentiators (e.g. gendered pronouns, postcode tiers).  
3. **Build matched profiles:** Synthetic but internally coherent inputs with equivalent histories.  
4. **Log outcomes systematically:** Capture timestamps, responses, and response latency.  
5. **Repeat for consistency:** Ensure observed variance is reproducible, not random noise.  

Every decoy is a *mirror* — its function is to reveal what the system prefers not to say aloud.  

---

## 📊 2. Measuring System Response  

When the input field becomes your microscope, attention to **response quality** is key.  
Observation should go beyond binary outcomes (“accepted” / “rejected”) and capture **behavioural texture** — tone, speed, follow-up prompts, or ranked results.  

### Metrics of response  
| Category | Example Signal | Possible Interpretation |
|-----------|----------------|--------------------------|
| **Latency** | Slower load times for certain attributes | Conditional pre-screening or extra verification layer |
| **Tone / Language Shift** | Change in language style of automated replies | Demographic inference bias or sentiment weighting |
| **Result Rank or Exposure** | Lower listing or visibility for certain profiles | Algorithmic suppression or shadow filtering |
| **Consistency Across Repeats** | Fluctuating responses to identical decoys | Randomisation camouflage or noise injection |

Each anomaly becomes a **clue** to the system’s behavioural logic — the unspoken hierarchy of its ruleset.  

---

## ⚖️ 3. Data Safety and Legal Boundaries  

Ethical decoy testing protects both people and platforms.  
It is not hacking; it is observation through simulation.  

### Safe practice checklist  
- ✅ Use **synthetic or anonymised data** only. Never reuse personal data without explicit consent.  
- ✅ Conduct experiments within **terms of service**; do not exploit vulnerabilities or trigger denial-of-service risk.  
- ✅ Avoid personally identifiable markers that could affect real users or organisations.  
- ✅ Keep a **transparency log** of methods and reasoning.  
- ✅ Share findings with regulators, watchdogs, or oversight boards before public release.  

Where ambiguity exists, consult a **data ethics review** or **legal advisor**.  
The aim is to reveal the *mechanism*, not to expose individuals.  

---

## 🧮 4. Publishing Findings Responsibly  

Decoy results are powerful evidence — but they can also be weaponised if misinterpreted.  
Responsible publication requires **contextual framing** and **non-identifying visualisation**.  

### Recommended practices  
- Publish aggregated results (e.g., percentage difference or trend lines) rather than raw submissions.  
- Use **heatmaps or differential plots** to highlight systemic bias without reproducing sensitive data.  
- Include an **Ethical Disclosure Statement** explaining the rationale, safeguards, and response process.  
- Where relevant, engage directly with the audited institution — ethical confrontation is often more effective than exposure.  

Remember: the goal is **structural transparency**, not reputational harm.  
A decoy experiment is a mirror, not a weapon.  

---

## 🧩 5. Toward a Culture of Verification  

When citizens, journalists, or researchers use decoy testing, they participate in a quiet revolution: **verification as civic duty**.  
Instead of waiting for institutions to admit bias, these experiments produce **proof of pattern** — small, repeatable acts of systemic literacy.  

In the long arc of the Polaris Protocol, Decoy Input Experiments form part of the *Verification Constellation*: tools that turn observation into accountability.  
By testing the edges of visibility, they remind systems that **being observed changes behaviour** — even for algorithms.  

---

## 🌌 Constellations  
🧪 🎯 🧿 🧾 🛠️ — testing, reverse engineering, ethics, verification.  

---

## ✨ Stardust  
decoy testing, reverse engineering, ethics, transparency, verification, audit design, civic science, hidden filters  

---

## 🏮 Footer  
*🧪 Decoy Input Experiments — Testing the Invisible Criteria* is a living node of the Polaris Protocol.  
It uses controlled experimentation to make invisible filters visible, building civic verification capacity across systems.  

> 📡 Cross-references: *TBC*  

*Survivor authorship is sovereign. Containment is never neutral.*  
_Last updated: 2025-10-20_  

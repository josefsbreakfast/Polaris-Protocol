# ğŸ’¾ Token Switching â€” Pseudonymisation Gone Wrong  
**First created:** 2025-11-11â€ƒ|â€ƒ**Last updated:** 2025-11-11  
*When anonymity mutates into error.*

---

## ğŸ§­ Orientation  

Pseudonymisation is meant to protect identity.  
Each person is given a **token** â€” a substitute key that links to their record without exposing who they are.  
But when those tokens are reissued, duplicated, or mis-mapped, systems lose track of whoâ€™s who.  
That slippage is **token switching**: the moment protection becomes distortion.

---

## ğŸ§© Core Definition  

> **Token switching** occurs when the pseudonym or hashed identifier assigned to one data subject  
> is later reused, replaced, or reinterpreted in another dataset without correct mapping.  

It can happen because of:
- System migrations and software upgrades  
- Human error during CSV export/import  
- Schema redesign (case-level â†’ person-level)  
- Poorly managed encryption keys or salts  
- Third-party research environments generating new tokens without a shared lookup table  

The result: *records belonging to different people are joined under one identity.*

---

## âš™ï¸ Technical Anatomy  

| Stage | Normal Process | Failure Mode |
|:------|:----------------|:-------------|
| **1ï¸âƒ£ Tokenisation** | Original identifiers hashed or replaced with unique pseudonyms. | Same pseudonym accidentally assigned to multiple people. |
| **2ï¸âƒ£ Mapping Table** | Secure lookup linking tokens to source IDs. | Lost, corrupted, or unencrypted; lookup mismatch. |
| **3ï¸âƒ£ Retokenisation** | New system generates fresh pseudonyms for imports. | Mapping between old and new pseudonyms not preserved. |
| **4ï¸âƒ£ Aggregation / Analysis** | Linked datasets join on token fields. | Joined on mismatched tokens â†’ data fusion or inversion. |

---

## ğŸ§® Example Cascade  

```mermaid
flowchart LR
A["Person A (victim) â†’ Token 001"] --> B["Database 1"]
C["Person B (offender) â†’ Token 002"] --> D["Database 2"]
B --> E["Migration script swaps token tables ğŸ”"]
D --> E
E --> F["Merged dataset: Token 001 now maps to both A & B âš ï¸"]
F --> G["Analytics output: profile contamination / narrative inversion"]
```

*Even anonymised systems can reproduce reputational harm when token lineage collapses.*

---

## ğŸª Consequences  

- **Identity fusion:** victim and offender data appear as one profile.  
- **Narrative inversion:** descriptors from one record are applied to another.  
- **Data poisoning:** analytic models train on false relationships.  
- **Legal exposure:** controller cannot prove accuracy (UK GDPR Art. 5(1)(d)).  

---

## ğŸ§° Safeguards & Mitigation  

| Layer | Control | Description |
|:------|:---------|:-------------|
| **Governance** | Maintain immutable token-lookup tables | Stored separately with access logs and encryption. |
| **Technical** | Role-based token namespaces | Separate pseudonym sets for victims, offenders, and staff. |
| **Procedural** | Audit token collisions quarterly | Run duplicate-token scans and rotation reviews. |
| **Research** | Require crosswalk verification before linkage | Confirm token lineage before joining multi-agency datasets. |

---

## ğŸ“Š Indicators of Risk  

- Sudden appearance of dual demographic values (two birth years, postcode drift).  
- Increase in â€œrole inversionâ€ errors during case analytics.  
- Token format changes (e.g., 16â†’32 characters) without notice.  
- Missing or expired encryption keys for legacy mapping tables.  

---

## ğŸŒŒ Constellations  

ğŸ’¾ ğŸ§© ğŸ§¬ âš™ï¸  

Token Switching connects to **Data Twinning** (identity fusion), **Data Lineage Review** (provenance tracing), and the **Token Integrity Audit** subfolder.  
It explains *how* a technical privacy tool can become a reputational hazard.

---

## âœ¨ Stardust  

pseudonymisation, data governance, justice datasets, mapping tables, encryption keys, data fusion, metadata contamination, identity integrity, ADR UK, token lineage, schema drift

---

## ğŸ® Footer  

*ğŸ’¾ Token Switching â€” Pseudonymisation Gone Wrong* is a living node of the Polaris Protocol.  
It documents the technical threshold where privacy safeguards turn into data-containment hazards, and where remediation must restore both **accuracy** and **directionality**.

> ğŸ“¡ Cross-references:  
> - [ğŸ§¬ Data Twinning â€” When Two Identities Become One Record](../ğŸ§©_System_Governance/ğŸ§¬_data_twinning_when_two_identities_become_one_record.md)  
> - [ğŸ§¾ Data Lineage Review](../ğŸ§©_System_Governance/ğŸ§¾_data_lineage_review.md)  
> - [ğŸª™ Token Integrity Audit](../ğŸ§©_System_Governance/ğŸª™_Token_Integrity_Audit/)  

*Survivor authorship is sovereign. Containment is never neutral.*  

_Last updated: 2025-11-11_
